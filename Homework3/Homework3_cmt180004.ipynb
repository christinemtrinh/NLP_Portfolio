{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Qrpqjr99QT",
        "outputId": "8e11b929-45e1-4196-efc2-af1b01cbf6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import needed packages\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.book import text4\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.metrics import BigramAssocMeasures\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" \n",
        "1. WordNet\n",
        "WordNet is a database for English words to be linked together based on their semantic, or meaning. It is similar\n",
        "to a thesarus except it is more specific about noting the relationship between words, rather than throwing them\n",
        "into a group with other words. Therefore, words may be \"more\" semantically close than others.\n",
        "\"\"\"\n",
        "\n",
        "# 2. Outputting all synsets for a chosen noun\n",
        "print('\\nChosen noun: cat')\n",
        "print(wn.synsets('cat'))\n",
        "cat = wn.synset('big_cat.n.01')\n",
        "\n",
        "# 3a. Extracting definition, usage examples, and lemmas\n",
        "print('Definition:', cat.definition())\n",
        "print('Examples:', cat.examples())\n",
        "print('Lemmas:', cat.lemmas())\n",
        "\n",
        "# 3b. Traversing up WordNet hierarchy\n",
        "print('Moving up WordNet Hierarchy:')\n",
        "l = cat.hypernyms()\n",
        "print('\\t', l)\n",
        "while l[0].hypernyms():\n",
        "  print('\\t', l[0].hypernyms())\n",
        "  l = l[0].hypernyms()\n",
        "\n",
        "\"\"\"\n",
        "Most nouns seems to eventually end at the synset entity. \n",
        "The further up the WordNet hierarchy goes, a less specific the noun is. \n",
        "This shows an \"is-a\" relationship of decreasing exclusivity.\n",
        "\"\"\"\n",
        "\n",
        "# 4. Extracting hypernyms, hyponyms, meronyms, holonyms, antonyms\n",
        "print('Hypernyms:', cat.hypernyms())\n",
        "print('Hyponyms:', cat.hyponyms())\n",
        "print('Meronyms:', cat.part_meronyms())\n",
        "print('Holonyms:', cat.member_holonyms())\n",
        "print('Antonyms:', cat.lemmas()[0].antonyms())\n",
        "\n",
        "# 5. Outputting all synsets for a chosen verb\n",
        "print('\\nChosen verb: sculpt')\n",
        "print(wn.synsets('sculpt'))\n",
        "sculpt = wn.synset('sculpt.v.02')\n",
        "\n",
        "# 6a. Extracting definition, usage examples, and lemmas\n",
        "print('Definition:', sculpt.definition())\n",
        "print('Examples:', sculpt.examples())\n",
        "print('Lemmas:', sculpt.lemmas())\n",
        "\n",
        "# 6b. Traversing up WordNet hierarchy\n",
        "print('Moving up WordNet Hierarchy:')\n",
        "l = sculpt.hypernyms()\n",
        "print('\\t', l)\n",
        "while l[0].hypernyms():\n",
        "  print('\\t', l[0].hypernyms())\n",
        "  l = l[0].hypernyms()\n",
        "\n",
        "\"\"\"\n",
        "Similar to nouns, verbs also seem to be organized in a manner than decreases in specifity moving up\n",
        "the WordNet hierarchy. Unlike nouns, verbs seem to bit a bit more vague and less extensive in connections.\n",
        "\"\"\"\n",
        "\n",
        "# 7. Finding other forms using Morphy\n",
        "print('Alternative word forms:')\n",
        "print('\\tsculpted ->', wn.morphy('sculpted', wn.VERB))\n",
        "print('\\tsculpting ->', wn.morphy('sculpting', wn.VERB))\n",
        "print('\\tsculpts ->', wn.morphy('sculpts', wn.VERB))\n",
        "print('\\tskelp ->', wn.morphy('skelp', wn.VERB))\n",
        "\n",
        "# 8. Wu-Palmer and Lesk on two \"similar\" words\n",
        "print('\\nChoose two similar words: fashionable and stylish')\n",
        "wn.synsets('fashionable')\n",
        "wn.synsets('stylish')\n",
        "fashionable = wn.synset('fashionable.a.01')\n",
        "stylish = wn.synset('stylish.a.01')\n",
        "\n",
        "print(\"Wu-Palmer:\", fashionable.wup_similarity(stylish))\n",
        "print('Example sentence: She is ostentatiously fashionable/stylish.')\n",
        "\n",
        "sentence = 'She is ostentatiously fashionable.'.split()\n",
        "print('Lesk (fashionable):', lesk(sentence, 'fashionable'))\n",
        "\n",
        "sentence = 'She is ostentatiously stylish.'.split()\n",
        "print('Lesk (stylish):', lesk(sentence, 'stylish')) \n",
        "\n",
        "\"\"\"\n",
        "The Wu-Palmer algorithm works by comparing distances between each synset and the lowest common hypernym. \n",
        "The similarity score can range from 0 < s <= 1. The Lesk algorithm returns the synset that explains the context \n",
        "a word is being used in a sentence. When I put the two words in the sentence, they gave the same coontext.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "SentiWordNet\n",
        "SWN is a resource for analyzing the sentiment of words, whether they are positive, neutral, or negative.\n",
        "It can be used by businesses or governments to make general conclusions about the feedback a populace provides.\n",
        "\"\"\"\n",
        "\n",
        "# 9. Pick emotionally charged word\n",
        "print('\\nChosen emotion word: elated')\n",
        "elated_list = list(swn.senti_synsets('elated'))\n",
        "for i in elated_list:\n",
        "  print(i)\n",
        "\n",
        "sentence='Coffee sounds perfect right now'\n",
        "print('\\nChosen sentence:', sentence)\n",
        "for i in sentence.split(): \n",
        "  context_word = lesk(sentence, i) \n",
        "  word_ss = swn.senti_synset(context_word.name())\n",
        "  if word_ss:\n",
        "    print(word_ss)\n",
        "\n",
        "\"\"\"\n",
        "I used the Lesk algorithm to determine the correct synset to derive the senti-synset. It seems that that were \n",
        "some errors which affected sentiment analysis. Seeing this, there is probably still a lot of improvements to make \n",
        "for this complex endeavor. \n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "Collocations are words that are often used together. \n",
        "A few common examples are \"high temperature\" or \"heavy rain.\"\n",
        "\"\"\"\n",
        "\n",
        "# 10. Collocation study with text4 \n",
        "tokens = word_tokenize(str(text4))\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = []\n",
        "for i in tokens:\n",
        "  if i.isalpha() and i not in stop_words:\n",
        "    filtered_tokens.append(i.lower())\n",
        "\n",
        "biagram_collocation = BigramCollocationFinder.from_words(filtered_tokens)\n",
        "biagram_collocation.nbest(BigramAssocMeasures.pmi, 5)\n",
        "biagram_collocation.score_ngrams(BigramAssocMeasures.pmi)\n",
        "\n",
        "\"\"\"\n",
        "All of the scores were equal to each other. PMI is calculated by finding the log probability of co-occurrence\n",
        "factored against the single probabilities of the two words to see if it is siimply a coincidence.\n",
        "The lower the score is, the more connected they are. 2.0 is not awfully low, so these collocations are not very strong.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpABPmVMqUxa",
        "outputId": "43c12f03-ebfc-4e56-e52f-54f9b168b8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chosen noun: cat\n",
            "[Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01'), Synset('cat.v.01'), Synset('vomit.v.01')]\n",
            "Definition: any of several large cats typically able to roar and living in the wild\n",
            "Examples: []\n",
            "Lemmas: [Lemma('big_cat.n.01.big_cat'), Lemma('big_cat.n.01.cat')]\n",
            "Moving up WordNet Hierarchy:\n",
            "\t [Synset('feline.n.01')]\n",
            "\t [Synset('carnivore.n.01')]\n",
            "\t [Synset('placental.n.01')]\n",
            "\t [Synset('mammal.n.01')]\n",
            "\t [Synset('vertebrate.n.01')]\n",
            "\t [Synset('chordate.n.01')]\n",
            "\t [Synset('animal.n.01')]\n",
            "\t [Synset('organism.n.01')]\n",
            "\t [Synset('living_thing.n.01')]\n",
            "\t [Synset('whole.n.02')]\n",
            "\t [Synset('object.n.01')]\n",
            "\t [Synset('physical_entity.n.01')]\n",
            "\t [Synset('entity.n.01')]\n",
            "Hypernyms: [Synset('feline.n.01')]\n",
            "Hyponyms: [Synset('cheetah.n.01'), Synset('jaguar.n.01'), Synset('leopard.n.02'), Synset('liger.n.01'), Synset('lion.n.01'), Synset('saber-toothed_tiger.n.01'), Synset('snow_leopard.n.01'), Synset('tiger.n.02'), Synset('tiglon.n.01')]\n",
            "Meronyms: []\n",
            "Holonyms: [Synset('felidae.n.01')]\n",
            "Antonyms: []\n",
            "\n",
            "Chosen verb: sculpt\n",
            "[Synset('sculpt.v.01'), Synset('sculpt.v.02')]\n",
            "Definition: shape (a material like stone or wood) by whittling away at it\n",
            "Examples: ['She is sculpting the block of marble into an image of her husband']\n",
            "Lemmas: [Lemma('sculpt.v.02.sculpt'), Lemma('sculpt.v.02.sculpture'), Lemma('sculpt.v.02.grave')]\n",
            "Moving up WordNet Hierarchy:\n",
            "\t [Synset('carve.v.01')]\n",
            "\t [Synset('cut.v.01'), Synset('shape.v.02')]\n",
            "\t [Synset('separate.v.02')]\n",
            "\t [Synset('move.v.02')]\n",
            "Alternative word forms:\n",
            "\tsculpted -> sculpt\n",
            "\tsculpting -> sculpt\n",
            "\tsculpts -> sculpt\n",
            "\tskelp -> None\n",
            "\n",
            "Choose two similar words: fashionable and stylish\n",
            "Wu-Palmer: 0.5\n",
            "Example sentence: She is ostentatiously fashionable/stylish.\n",
            "Lesk (fashionable): Synset('stylish.a.01')\n",
            "Lesk (stylish): Synset('stylish.a.01')\n",
            "\n",
            "Chosen emotion word: elated\n",
            "<elate.v.01: PosScore=0.5 NegScore=0.0>\n",
            "<elated.a.01: PosScore=0.625 NegScore=0.25>\n",
            "<elated.s.02: PosScore=0.5 NegScore=0.375>\n",
            "\n",
            "Chosen sentence: Coffee sounds perfect right now\n",
            "<coffee_bean.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<voice.v.02: PosScore=0.0 NegScore=0.0>\n",
            "<perfective.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<veracious.s.02: PosScore=0.875 NegScore=0.0>\n",
            "<nowadays.r.01: PosScore=0.25 NegScore=0.0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('address', 'corpus'), 2.0),\n",
              " (('inaugural', 'address'), 2.0),\n",
              " (('text', 'inaugural'), 2.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    }
  ]
}